# Chapter 7: Reliability under Uncertainty  

![Image 7 - Reliability](../images/7.%20Reliability.png)  

## Overview

Enterprises operate under constraints like regulatory, legal, reputational. Agents must embody those boundaries.  

How is this enforced?  

Policy Codification: Encode company policies and ethical rules as first-class constraints in the agentâ€™s reasoning engine. For example: â€œNever approve spend above $10,000 without two signatures,â€ or, â€œNever share PII outside the EU.â€  

Dynamic Policy Updates: As regulations evolve, agents must be able to adapt without wholesale retraining. This demands modular architectures, where policy layers are abstracted from underlying ML models.  

Human Override: At all times, ensure a path for human intervention and override. Trust is built not just on autonomy, but on the assurance that control can be regained.  


## Resources and Further Reading

### Online Resources
- ğŸŒ [Human-in-the-loop](https://learn.microsoft.com/en-us/semantic-kernel/frameworks/process/examples/example-human-in-loop)  
- ğŸŒ [Build AI Agents in Azure Logic Apps](https://techcommunity.microsoft.com/blog/integrationsonazureblog/%F0%9F%93%A2announcing-agent-loop-build-ai-agents-in-azure-logic-apps-%F0%9F%A4%96/4415052)  

## Next Steps

Continue your learning journey:

[â† Chapter 6](chapter-06.md) | [Chapter 8 â†’](chapter-08.md)

---

<div class="card">

**Questions or feedback?** Join the discussion on our [GitHub repository](https://github.com/codess-aus/OREDEV-Building-Trustworthy-AI) or connect with the community.

</div>

# Chapter 20: Automated Red Team Scanning

![Automated Red Teaming workflow (animated)](../images/20.%20auto%20red-teaming.gif){ .gif-figure }
<div class="gif-caption">Figure: Automated Red Teaming workflow (animated)</div>  

## Overview  

So I am talking about evaluating, monitoring and managing your agents â€“ but one of the reasons this is so critical is because the jobs they can do now, include working side by side with our own security and compliance and SRE staff. We need to be able to trust them because they are working with us on tasks like Red Teaming â€“ to test the very systems they work on.  

Automated scans to empower security professionals and ML engineers to proactively find risks in their generative AI systems faster with integrations of PyRIT into Azure AI Foundry.  


## Resources and Further Reading  

- ğŸŒ [Microsoft AI Red Team](https://learn.microsoft.com/en-us/security/ai-red-team/)  
- ğŸŒ [Red Teaming](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/red-teaming)  
- ğŸŒ [AI Red Teaming Agent](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/ai-red-teaming-agent)  

## Next Steps

Continue your learning journey:

[â† Chapter 19](chapter-19.md) | [Chapter 21 â†’](chapter-21.md)

---

<div class="card">

**Questions or feedback?** Join the discussion on our [Building Trustworthy AI](https://github.com/codess-aus/OREDEV-Building-Trustworthy-AI) or connect with the community.

</div>

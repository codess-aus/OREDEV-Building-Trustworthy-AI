# Chapter 21: Establish On-going Verification Loops

![Image 21 - Verification Loops](../images/21.%20Verification%20Loops.png)  

## Overview

Powers visibility, monitoring and optimization across the entire AI development lifecycle
The bottom line is that measurement is critical to iterative development and getting apps into production.

Periodic Audits: Review agent behaviour regularly, not just after incidents. Use agentic automated tools and human review.

Incident Response Integration: When agents go off-script, the process for root cause analysis and correction must be as robust as incident management for production systems.

Reward Learning: Incentivize agents (via their optimization objectives) to not just maximize task outcomes, but also minimize negative feedback and override rates.

## Resources and Further Reading

### Online Resources  

- üåê [Plan and prepare to develop AI solutions on Azure](https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/)


## Next Steps

Continue your learning journey:

[‚Üê Chapter 20](chapter-20.md) | [Chapter 22 ‚Üí](chapter-22.md)

---

<div class="card">

**Questions or feedback?** Join the discussion on our [GitHub repository](https://github.com/codess-aus/OREDEV-Building-Trustworthy-AI) or connect with the community.

</div>

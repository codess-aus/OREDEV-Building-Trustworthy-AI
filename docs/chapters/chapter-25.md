# Chapter 25: Responsible AI practices in prompt engineering  

![Image 25 - Prompt Engineering](../images/25.%20Prompt%20Engineering.png)  

## Overview  

Thinking back to all the different types of risk that we talked about earlier.  

Much of prompt engineering is devoted to implementing best practices for safety.  

We have found it helpful to build a dedicated part in the metaprompt addressing each and every one of them.  

We‚Äôve learned that even small changes to a system message can have an outsized impact.
For example, it is far more effective to tell a model what not to do AND what to do instead than simply telling it what not to do.  

We‚Äôve baked these learnings into Azure AI Foundry playground for you, so you don‚Äôt need to start from scratch when building a system message.  

## Resources and Further Reading

- üåê [Prompt Engineering Concepts](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/prompt-engineering)
- üåê [Introduction to prompt engineering with GitHub Copilot](https://learn.microsoft.com/en-us/training/modules/introduction-prompt-engineering-with-github-copilot/)


## Next Steps

Continue your learning journey:

[‚Üê Chapter 24](chapter-24.md) | [Chapter 26 ‚Üí](chapter-26.md)

---

**Questions or feedback?** Join the discussion on our [GitHub repository](https://github.com/codess-aus/OREDEV-Building-Trustworthy-AI) or connect with the community.


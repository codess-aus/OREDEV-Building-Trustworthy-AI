# Chapter 14: Design for Observable Trust Signals  

![Image 14 - Observe](../images/14.%20Observe.png)  

## Overview

Continuously improve and monitor your AI Agents:  

We need to design our systems so that trust is not just assumed, but observable and measurable. In practice, this means continuously improving and monitoring our AI agentsâ€”not just for performance, but for impact, quality, safety, and cost.  

With tools like Azure AI Foundry, we can track key operational and evaluation metrics in real timeâ€”such as groundedness, relevance, fluency, and intent resolution. These metrics help us spot issues early, ensure our AI is behaving as intended, and give us the confidence to develop and operate AI responsibly in production.  

Ultimately, designing for observable trust signals means making trust visibleâ€”not just to developers, but to business users and stakeholders as well. Itâ€™s about building AI that earns trust every day, through transparency, accountability, and continuous improvement  


## Resources and Further Reading

![Observable Trust Signals](../images/14.%20observable%20systems.png) 

### Online Resources
- ğŸŒ [Zero Trust Best Practice Frameworks](https://learn.microsoft.com/en-us/training/modules/introduction-zero-trust-best-practice-frameworks/)
- ğŸŒ [Building Observeable Systems](https://learn.microsoft.com/en-us/azure/architecture/example-scenario/monitoring/monitoring-observable-systems-media)  


## Next Steps

Continue your learning journey:

[â† Chapter 13](chapter-13.md) | [Chapter 15 â†’](chapter-15.md)

---

<div class="card">

**Questions or feedback?** Join the discussion on our [GitHub repository](https://github.com/codess-aus/OREDEV-Building-Trustworthy-AI) or connect with the community.

</div>

# Chapter 4: Microsoft Trustworthy AI  

![Image 4 - Trustworthy](../images/4.%20Trustworthy.png)  

## Overview

At Microsoft, we believe Trustworthy AI is only possible when we combine our commitments, such as our Secure Future Initiative and AI principles, with our product capabilities to help customers unlock AI transformation with confidence.

### Microsoft's Trustworthy AI Framework

Our approach combines principled commitments with practical tools:

- **AI Principles**: Fairness, reliability, privacy, security, inclusiveness, transparency, and accountability
- **Secure Future Initiative**: Enterprise-grade security built into every AI service
- **Product Integration**: Principles embedded in Azure AI Foundry, GitHub, and Microsoft 365
- **Continuous Innovation**: Ongoing research and development in responsible AI technologies

Azure AI Foundry operationalizes these principles through:
- **Built-in Content Safety**: Automatic filtering of harmful content in inputs and outputs
- **Evaluation Frameworks**: Tools to measure quality, safety, and fairness metrics
- **Transparency Features**: Model cards, data sheets, and audit trails
- **Governance Controls**: Policy enforcement, access management, and compliance reporting

With Azure and GitHub, responsible AI isn't aspirational‚Äîit's operational. You get the tools, guardrails, and visibility needed to deploy AI systems that meet both your standards and your users' expectations.

## Resources and Further Reading

### Online Resources
- üåê [Secure Future Initiative](https://www.microsoft.com/en-us/trust-center/security/secure-future-initiative)  
- üåê [Responsible AI Principles](https://www.microsoft.com/en-us/ai/principles-and-approach)  


## Next Steps

Continue your learning journey:

[‚Üê Chapter 3](chapter-03.md) | [Chapter 5 ‚Üí](chapter-05.md)

---

**Questions or feedback?** Join the discussion on our [GitHub repository](https://github.com/codess-aus/OREDEV-Building-Trustworthy-AI) or connect with the community.

